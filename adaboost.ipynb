{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "COLLABORATORS = \"Alexander Walla, Marc-Alexander Richts\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Intro\n",
    "\n",
    "*Boosting* bezeichnet in Machine Learning einen \"[ensemble](https://de.wikipedia.org/wiki/Ensemble_learning) [Metaalgorithmus](https://de.wikipedia.org/wiki/Metaheuristik)\". Ensemble Learning verwendet mehrere Lernalgorithmen, um prädikative [Inferenz](https://de.wikipedia.org/wiki/Statistische_Inferenz) (Vorhersagen) im Vergleich zu einzelnen Lernalgorithmen zu verbessern. Boosting ist eine Art von Implementation von Ensemble Learning um mehrere schwache Klassifikatoren zu einem leistungsfähigen Klassifikator zusammenzufügen. Beim Boosting werden die Prädikatoren in \"Reihe geschaltet\" und nacheinander trainiert, sodass jeder Prädikator versucht die Fehler des vorherigen Prädikators zu beheben.\n",
    "\n",
    "Die einzelnen schwachen Klassifikatoren müssen nur leicht besser als zufälliges raten sein."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AdaBoost\n",
    "\n",
    "AdaBoost (kurz für \"Adaptive Boost\") ist eine Boostingmethode, die den vorherigen Prädikator korrigiert, indem der nachfolgende Prädikator seinen Bias (Gewichte) zu den im Vorgängerprädikator nicht beachteten Trainingsdatenpunkten schiebt. Damit fokussieren sich die in der Kette später kommenden Prädikatoren mehr und mehr auf die schwierigeren Fälle.\n",
    "\n",
    "Je nach Genauigkeit der einzelnen Prädikatoren werden diese gewichtet. Je genauer ein Prädikator ist, desto höher ist sein Gewicht. Bei einer Genauigkeit, die zufälligem raten entspricht, bekommt der Prädikator ein Gewicht von ``0``. Wenn der Prädikator eine niedrigere Genauigkeit als 50% Trefferquote hat, bekommt er ein negatives Gewicht.\n",
    "\n",
    "**Es gibt also zwei Arten von Gewichten**:\n",
    "- Die Trainingsdaten bekommen Gewichte. Zuerst sind diese Datenpunkte alle neutral gewichtet $ 1 / m $, das bedeutet, der erste Prädikator wird auf die originalen Daten trainiert. Danach wird die gewichtete Fehlerquote wie folgt auf die Trainingsdaten berechnet.\n",
    "- Alle Prädikatoren bekommen je nach Genauigkeit ein hohes oder niedriges Gewicht. Dieses wird am Ende im Ensemble verwendet, um eine Mehrheit auszurechnen. Das Gewicht eines Prädikators $ a_{j} $ berechnet sich wie folgt:\n",
    "\n",
    "$$ a_{j} = n log \\frac{1 - r_{j}}{r_{j}} $$\n",
    "$$(Géron, 2020, p. 251)$$\n",
    "\n",
    "- Der Hyperparameter $ n $ stellt hier die Lernrate dar, der standardmäßig auf 1 gesetzt ist.\n",
    "- $ r_{j} $ beschreibt die Fehlerrate\n",
    "\n",
    "\n",
    "Danach werden die falsch klassifizierten Datenpunkte *geboosted*; sprich, die Datenpunkte bekommen ein höheres Gewicht. Wie oben bereits beschrieben, verschiebt sich dadurch der Bias auf die Datenpunkte auf die schwierigeren Cases.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Anwendung mit SciKit\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Literaturverzeichnis\n",
    "[1] Géron, A. (2020). Praxiseinstieg Machine Learning mit Scikit-Learn, Keras und TensorFlow: Konzepte, Tools und Techniken für intelligente Systeme (Aktuell zu TensorFlow 2) [E-book]. Dpunkt.Verlag GmbH."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}